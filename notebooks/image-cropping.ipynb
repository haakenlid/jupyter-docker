{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in /home/jupyter/.local/lib/python3.6/site-packages (5.3.0)\r\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --user Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "from io import BytesIO\n",
    "from IPython.display import HTML, display\n",
    "import random\n",
    "import itertools\n",
    "import glob\n",
    "import cv2\n",
    "import base64\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/share/OpenCV/haarcascades\n"
     ]
    }
   ],
   "source": [
    "HAARCASCADES = (Path(cv2.__file__) / '../../../../share/OpenCV/haarcascades').resolve()\n",
    "print(HAARCASCADES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoundingBox:\n",
    "\n",
    "    \"\"\"Rectangular bounding box\"\"\"\n",
    "\n",
    "    def __init__(self, left, top, right, bottom):\n",
    "        assert top < bottom and left < right, \"Width and height must be greater than zero\"\n",
    "        self.left = left\n",
    "        self.top = top\n",
    "        self.right = right\n",
    "        self.bottom = bottom\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            '{self.__class__.__name__}'\n",
    "            '(left={self.left}, top={self.top}, right={self.right}, bottom={self.bottom})'\n",
    "        ).format(self=self)\n",
    "\n",
    "    def __add__(self, other):\n",
    "        \"\"\"BoundingBox containing both boxes\"\"\"\n",
    "        return self.__class__(\n",
    "            left=min(self.left, other.left),\n",
    "            top=min(self.top, other.top),\n",
    "            right=max(self.right, other.right),\n",
    "            bottom=max(self.bottom, other.bottom),\n",
    "        )\n",
    "\n",
    "    def __radd__(self, other):\n",
    "        return self\n",
    "\n",
    "    def __and__(self, other):\n",
    "        \"\"\"Intersection\"\"\"\n",
    "        return self.__class__(\n",
    "            left=max(self.left, other.left),\n",
    "            top=max(self.top, other.top),\n",
    "            right=min(self.right, other.right),\n",
    "            bottom=min(self.bottom, other.bottom),\n",
    "        )\n",
    "\n",
    "    def __contains__(self, point):\n",
    "        x, y = point\n",
    "        return self.top <= x <= self.bottom and self.left <= y <= self.right\n",
    "\n",
    "    def __mul__(self, factor):\n",
    "        \"\"\"Multiply all dimensions by factor\"\"\"\n",
    "        x, y = self.center\n",
    "        w, h = self.width * factor, self.height * factor \n",
    "        return self.__class__(\n",
    "            left=x - w / 2,\n",
    "            top=y - h / 2 ,\n",
    "            right=x + w / 2,\n",
    "            bottom=y + h / 2,\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def width(self):\n",
    "        return self.right - self.left\n",
    "\n",
    "    @width.setter\n",
    "    def width(self, value):\n",
    "        self.left, self.right = (self.center[0]+x*value*.5 for x in [-1,1])\n",
    "\n",
    "    @property\n",
    "    def height(self):\n",
    "        return self.bottom - self.top\n",
    "\n",
    "    @height.setter\n",
    "    def height(self, value):\n",
    "        self.top, self.bottom = (self.center[1]+x*value*.5 for x in [-1,1])\n",
    "\n",
    "    @property\n",
    "    def diagonal(self):\n",
    "        \"\"\"Length of diagonal\"\"\"\n",
    "        return (self.width**2 + self.height**2)**0.5\n",
    "\n",
    "    @property\n",
    "    def ratio(self):\n",
    "        \"\"\"Aspect ratio\"\"\"\n",
    "        return self.width / self.height\n",
    "\n",
    "    @property\n",
    "    def size(self):\n",
    "        \"\"\"Area of BoundingBox\"\"\"\n",
    "        return self.width * self.height\n",
    "\n",
    "    @property\n",
    "    def center(self):\n",
    "        \"\"\"Center point of box (x, y)\"\"\"\n",
    "        return (self.right + self.left) / 2, (self.bottom + self.top) / 2\n",
    "\n",
    "    @property\n",
    "    def geometry(self):\n",
    "        return self.left, self.top, self.right, self.bottom\n",
    "    \n",
    "    def inside(self, other, fit=True):\n",
    "        limit = 1e-15 # floating point math requires some imprecision\n",
    "        if not fit:\n",
    "            assert self.width - other.width > -limit\n",
    "            assert self.height - other.height > -limit\n",
    "            \n",
    "        width = min(self.width, other.width, other.ratio * self.height) \n",
    "        height = width * other.ratio**-1.0\n",
    "        left = sorted([self.left, self.right - width, other.center[0] - width/2])[1]\n",
    "        top = sorted([self.top, self.bottom - height, other.center[1] - height/2])[1]\n",
    "        right = left + width \n",
    "        bottom = top + height\n",
    "        return self.__class__(left, top, right, bottom)\n",
    "            \n",
    "    def outside(self, other, fit=True):\n",
    "        limit = 1e-15 # floating point math requires some imprecision\n",
    "        if not fit:\n",
    "            assert other.width - self.width > -limit\n",
    "            assert other.height - self.height > -limit\n",
    "            \n",
    "        width = max(self.width, other.width, other.ratio * self.height) \n",
    "        height = width * other.ratio**-1.0\n",
    "        left = sorted([self.left, self.right - width, other.center[0] - width/2])[1]\n",
    "        top = sorted([self.top, self.bottom - height, other.center[1] - height/2])[1]\n",
    "        right = left + width\n",
    "        bottom = top + height \n",
    "        return self.__class__(left, top, right, bottom)\n",
    "\n",
    "class ImageBoundingBox(BoundingBox):\n",
    "\n",
    "    \"\"\"Bounding box with absolute pixel values\"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def from_relative(cls, box, image_width, image_height, contain=True):\n",
    "        if contain:\n",
    "            box &= BoundingBox(0, 0, 1, 1)\n",
    "\n",
    "        return cls(\n",
    "            left=box.left * image_width,\n",
    "            top=box.top * image_height,\n",
    "            right=box.right * image_width,\n",
    "            bottom=box.bottom * image_height,\n",
    "        )\n",
    "\n",
    "    def to_relative(self, image_width, image_height, contain=True):\n",
    "        \"\"\"Convert to a RelativeBoundingBox\"\"\"\n",
    "        box = BoundingBox(\n",
    "            left=self.left / image_width,\n",
    "            top=self.top / image_height,\n",
    "            right=self.right / image_width,\n",
    "            bottom=self.bottom / image_height,\n",
    "        )\n",
    "        if contain:\n",
    "            box &= BoundingBox(0, 0, 1, 1)\n",
    "\n",
    "        return box\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "class BaseCropEngine:\n",
    "\n",
    "    def __init__(self, padding=0.6):\n",
    "        self.bounds = BoundingBox(0, 0, 1, 1) * padding\n",
    "\n",
    "    @staticmethod\n",
    "    def opencv_image(image_file, size, color=cv2.COLOR_BGR2GRAY):\n",
    "        cvimg = cv2.imread(image_file)\n",
    "        height, width = cvimg.shape[:2]\n",
    "        if width > height:\n",
    "            height, width = size * height // width, size\n",
    "        else:\n",
    "            height, width = size, size * width // height\n",
    "        cvimg = cv2.resize(cvimg, (width, height))\n",
    "        return cv2.cvtColor(cvimg, color)\n",
    "\n",
    "    def find_features(self, image_file):\n",
    "        return [self.bounds, self.bounds * 0.5]\n",
    "\n",
    "\n",
    "class FeatureCropEngine(BaseCropEngine):\n",
    "\n",
    "    def __init__(self, n=10, padding=1.2, size=200, extra_kwargs=None):\n",
    "        self.imagesize = size\n",
    "        self.padding = padding\n",
    "        arguments = dict(\n",
    "            nfeatures=n,\n",
    "            scaleFactor=1.5,\n",
    "            patchSize=self.imagesize // 10,\n",
    "            edgeThreshold=self.imagesize // 10,\n",
    "            WTA_K=2,\n",
    "            scoreType=cv2.ORB_FAST_SCORE,\n",
    "        )\n",
    "        if extra_kwargs:\n",
    "            arguments.update(extra_kwargs)\n",
    "        self.feature_detector = cv2.ORB_create(**arguments)\n",
    "\n",
    "    def find_features(self, image_file):\n",
    "        cvimg = self.opencv_image(image_file, self.imagesize)\n",
    "        height, width = cvimg.shape[:2]\n",
    "\n",
    "        keypoints, desc = self.feature_detector.detectAndCompute(\n",
    "            image=cvimg, mask=None)\n",
    "        keyfunc = lambda kp: kp.size * kp.response * kp.response\n",
    "        keypoints = sorted( keypoints,  key=keyfunc, reverse=True )\n",
    "        \n",
    "        boxes = []\n",
    "        for keypoint in keypoints:\n",
    "            radius = keypoint.size / 2\n",
    "            x = keypoint.pt[0]\n",
    "            y = keypoint.pt[1]\n",
    "            box = ImageBoundingBox(\n",
    "                left=x-radius,\n",
    "                top=y-radius, \n",
    "                right=x+radius, \n",
    "                bottom=y+radius,\n",
    "            )\n",
    "            box *= self.padding\n",
    "            box = box.to_relative(width, height) \n",
    "            boxes.append(box)\n",
    "            \n",
    "        return boxes\n",
    "\n",
    "\n",
    "\n",
    "class FaceCropEngine(BaseCropEngine):\n",
    "\n",
    "    cascade_files = str(HAARCASCADES) + '/haarcascade_{}.xml'\n",
    "    default_classifiers = ['frontalface_default', 'profileface']\n",
    "    \n",
    "    def __init__(self, classifiers=None, n=100, size=400, padding=1.3):\n",
    "        if classifiers is None:\n",
    "            classifiers = self.default_classifiers[:]\n",
    "        self.classifiers = []\n",
    "        for classifier_name in classifiers:\n",
    "            cascade_file = self.cascade_files.format(classifier_name)\n",
    "            assert pathlib.Path(cascade_file).exists(), 'file %s not found'% cascade_file\n",
    "            self.classifiers.append(cv2.CascadeClassifier(cascade_file))\n",
    "            \n",
    "        self.imagesize = size\n",
    "        self.minsize = (self.imagesize // 15, self.imagesize // 15)\n",
    "        self.padding = padding\n",
    "        self.number = n\n",
    "\n",
    "    def find_features(self, image_file):\n",
    "        cvimg = self.opencv_image(image_file, self.imagesize)\n",
    "        height, width = cvimg.shape[:2]\n",
    "        \n",
    "        faces = []\n",
    "        for classifier in self.classifiers:\n",
    "            faces.extend(\n",
    "                classifier.detectMultiScale(\n",
    "                    cvimg, \n",
    "                    minSize=self.minsize, \n",
    "                    minNeighbors=8,\n",
    "                ))\n",
    "        boxes = []\n",
    "        for l, t, w, h in faces:\n",
    "            box = ImageBoundingBox(left=l, top=t, right=l + w, bottom=t + h)\n",
    "            box *= self.padding\n",
    "            box = box.to_relative(width, height)\n",
    "            boxes.append(box)\n",
    "            \n",
    "        boxes = sorted(boxes, key=lambda b: b.size, reverse=True)\n",
    "        return boxes[:self.number]\n",
    "\n",
    "\n",
    "class HybridEngine(BaseCropEngine):\n",
    "\n",
    "    def __init__(self, padding=1.3):\n",
    "        self.face_engine = FaceCropEngine(padding=padding)\n",
    "        self.feature_engine = FeatureCropEngine(padding=padding)\n",
    "        self.extra_engine = FeatureCropEngine(n=5, padding=padding/2)\n",
    "\n",
    "    def find_features(self, image_file, plot=None):\n",
    "        features = self.face_engine.find_features(image_file) \n",
    "        if not features:\n",
    "            return self.feature_engine.find_features(image_file)\n",
    "        if sum(features).size < 0.15:\n",
    "            features += self.extra_engine.find_features(image_file)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps, ImageDraw\n",
    "\n",
    "def plot_box_on_image(image, box=None, color='white', shape='b', grid=2, width=1, invert=False, antialias=2):\n",
    "    width = width * antialias / 2\n",
    "    if box is None:\n",
    "        box = BoundingBox(0,0,1,1)\n",
    "    if isinstance(box, ImageBoundingBox):\n",
    "        box = ImageBoundingBox.to_relative(box, image.width, image.height)\n",
    "    overlay = Image.new(\n",
    "        size=[int(dim * antialias) for dim in image.size],\n",
    "        mode='RGBA', color=(0,0,0,0))\n",
    "    \n",
    "    box = ImageBoundingBox.from_relative(box, overlay.width, overlay.height)\n",
    "    draw = ImageDraw.Draw(overlay)\n",
    "    \n",
    "    def line(*args):\n",
    "        draw.line(args, fill=color, width=int(2*width))\n",
    "    \n",
    "    if 'o' in shape:\n",
    "        b0 = [v - width for v in box.geometry]\n",
    "        b1 = [v + width for v in box.geometry]\n",
    "        draw.ellipse(b0[:2] + b1[2:], fill=color)\n",
    "        draw.ellipse(b1[:2] + b0[2:], fill=(0,0,0,0))\n",
    "        \n",
    "    if 'b' in shape:\n",
    "        l, t, r, b = box.geometry\n",
    "        line(l+width, t, r-width, t)\n",
    "        line(l+width, b, r-width, b)\n",
    "        line(l, t-width, l, b+width)\n",
    "        line(r, t-width, r, b+width)\n",
    "        \n",
    "    if 'x' in shape:\n",
    "        line(box.left, box.top, box.right, box.bottom)\n",
    "        line(box.right, box.top, box.left, box.bottom)\n",
    "        \n",
    "    if '+' in shape:\n",
    "        x, y = box.center\n",
    "        length = 20*antialias\n",
    "        gap = 5*antialias\n",
    "        line(x-length, y, x-gap, y)\n",
    "        line(x+length, y, x+gap, y)\n",
    "        line(x, y-length, x, y-gap)\n",
    "        line(x, y+length, x, y+gap)\n",
    "        \n",
    "    if grid and '#' in shape:\n",
    "        divs = grid + 1\n",
    "        dw = box.width / divs\n",
    "        dh = box.height / divs\n",
    "        for n in range(1, divs):\n",
    "            x = box.left + n * dw\n",
    "            y = box.top + n * dh\n",
    "            line(box.left, y, box.right, y)\n",
    "            line(x, box.top, x, box.bottom)\n",
    "            \n",
    "    overlay = overlay.resize(image.size, Image.LANCZOS)\n",
    "    mask = overlay\n",
    "    if invert:\n",
    "        overlay = ImageOps.invert(image)\n",
    "    image.paste(overlay, mask=mask)\n",
    "\n",
    "def test_box_and_plotting(image_file):\n",
    "    image = Image.open(image_file)\n",
    "    image.thumbnail((600, 400))\n",
    "    box = None\n",
    "    #plot_box_on_image(image, box, width=.4, shape='#', color='white', grid=99, antialias=5)\n",
    "    plot_box_on_image(image, box, width=.8, shape='#', color='white', grid=9, antialias=3)\n",
    "    box = BoundingBox(.6,.1,.9,.6) \n",
    "    box = ImageBoundingBox.from_relative(box * 2, image.width, image.height) \n",
    "    plot_box_on_image(image, box, width=5, shape='ox', color=(256,0,256,128), antialias=4)\n",
    "    box.height = box.width = 300\n",
    "    plot_box_on_image(image, box * 0.5, width=3, shape='o', antialias=4)\n",
    "    plot_box_on_image(image, box, width=20, shape='b+', invert=True)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def close_crop(image, geometry, center, shape):\n",
    "    cx = center[0] * image.width \n",
    "    cy = center[1] * image.height\n",
    "    cropbox = ImageBoundingBox.from_relative(\n",
    "        BoundingBox(*geometry), image.width, image.height)\n",
    "    \n",
    "    output_ratio = shape[0] / shape[1]\n",
    "    image_ratio = image.width / image.height\n",
    "\n",
    "    if image_ratio > output_ratio:\n",
    "        w1 = image.height * output_ratio\n",
    "    else:\n",
    "        w1 = image.width\n",
    "        \n",
    "    if cropbox.ratio > output_ratio:\n",
    "        w2 = cropbox.width\n",
    "    else:\n",
    "        w2 = cropbox.height * output_ratio\n",
    "\n",
    "    width = min(w1, w2)\n",
    "    height = width / output_ratio\n",
    "    \n",
    "    if width > cropbox.width:\n",
    "        ccx = [width / 2, image.width - width / 2, cropbox.center[0]]\n",
    "    else:\n",
    "        ccx = [cropbox.left + width / 2, cropbox.right - width / 2, cx ]\n",
    "\n",
    "    if height > cropbox.height:\n",
    "        ccy = [height / 2, image.height - height / 2, cropbox.center[1]]\n",
    "    else:\n",
    "        ccy = [cropbox.top + height / 2, cropbox.bottom - height / 2, cy ]\n",
    "\n",
    "    cx, cy = sorted(ccx)[1], sorted(ccy)[1]\n",
    "\n",
    "    box = BoundingBox(\n",
    "        left = cx - width / 2,\n",
    "        right = cx + width / 2,\n",
    "        top = cy - height / 2,\n",
    "        bottom = cy + height / 2,\n",
    "    )\n",
    "    return box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_html_img(image, _id=None, style={}):\n",
    "    b = BytesIO()\n",
    "    image.convert('RGB').save(b, 'PNG')\n",
    "    raw = b.getvalue()\n",
    "    attrs = {}\n",
    "    if style:\n",
    "        attrs['style'] = '\"{}\"'.format(\n",
    "            ';'.join('{}: {}'.format(key, value) for key, value in style.items()))\n",
    "    if _id:\n",
    "        attrs['id'] = _id\n",
    "        attrs['title'] = _id\n",
    "    data = base64.encodebytes(raw).decode('ascii').replace(\"\\n\", \"\")\n",
    "    attrs['src'] = '\"data:image/png/;base64,{}\"'.format(data)\n",
    "    html = '<img {} />'.format(\n",
    "        ' '.join('{}={}'.format(k, v) for k, v in attrs.items()))\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_html(images):\n",
    "    html = []\n",
    "   \n",
    "    for image in images:\n",
    "        html.append(image_crops_to_htmldiv(image))\n",
    "        print('#', end = '')\n",
    "    return '\\n'.join(html)\n",
    "\n",
    "def image_crops_to_htmldiv(image):\n",
    "    height = 150\n",
    "    ratios = 0.5, 1, 2\n",
    "    widths = (int(height * ratio) for ratio in ratios)\n",
    "    center = image.features[0].center\n",
    "    image_id = image.filename\n",
    "    cropbox = sum(image.features) * 1.2\n",
    "    crop_thumbs = []\n",
    "    feature_thumbs = []\n",
    "    for width in widths:\n",
    "        shape = (width, height)\n",
    "        box = close_crop(\n",
    "            image = image,\n",
    "            geometry = cropbox.geometry,\n",
    "            center = center,\n",
    "            shape = shape,\n",
    "        )\n",
    "        thumb = image.crop([int(val) for val in box.geometry]).resize(shape)\n",
    "        crop_thumbs.append(image_to_html_img(thumb))\n",
    "            \n",
    "    feature_thumb_size = [int(height*.5)] * 2\n",
    "    imageclone = image.copy()  \n",
    "    image.thumbnail((height*3, height*3))     \n",
    "    plot_box_on_image(image, cropbox, color='white', width=2, shape='b', antialias=4)\n",
    "    plot_box_on_image(image, image.features[0], color='yellow', width=1, shape='+', antialias=4)\n",
    "            \n",
    "    for index, feature in enumerate(image.features):\n",
    "        box = ImageBoundingBox.from_relative(feature, imageclone.width, imageclone.height)\n",
    "        thumb = imageclone.crop([int(v) for v in box.geometry])\n",
    "        thumb.thumbnail(feature_thumb_size)\n",
    "        plot_box_on_image(image, feature, shape='o', antialias=4)\n",
    "        plot_box_on_image(thumb, None, shape='+', antialias=4)\n",
    "        feature_id = '{}-{}'.format(image_id, index)\n",
    "        feature_thumbs.append(image_to_html_img(thumb, _id=feature_id))\n",
    "            \n",
    "    SNIPPET = \"\"\"\n",
    "    <div class=\"group\">\n",
    "        <div class=\"thumbs\">\n",
    "            <div class=\"crops\">{crops}</div>\n",
    "            <div class=\"features\">{features}</div>\n",
    "        </div>\n",
    "        <div class=\"sourceimage\">{sourceimage}</div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    sourceimage = image_to_html_img(image, _id=image_id) \n",
    "    html = SNIPPET.format(\n",
    "        crops = ''.join(crop_thumbs),\n",
    "        features = ''.join(feature_thumbs),\n",
    "        sourceimage=sourceimage,\n",
    "    )\n",
    "    return html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "file /usr/local/lib/share/OpenCV/haarcascades/haarcascade_frontalface_default.xml not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-324ebe9c6cfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./*.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-324ebe9c6cfe>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(n, image_files, random_order, indexes)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mresize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m800\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m800\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mcrop_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHybridEngine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mimage_files\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-a0d3af5744a7>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, padding)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFaceCropEngine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFeatureCropEngine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFeatureCropEngine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-a0d3af5744a7>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, classifiers, n, size, padding)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mclassifier_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclassifiers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mcascade_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcascade_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcascade_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'file %s not found'\u001b[0m\u001b[0;34m%\u001b[0m \u001b[0mcascade_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCascadeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcascade_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: file /usr/local/lib/share/OpenCV/haarcascades/haarcascade_frontalface_default.xml not found"
     ]
    }
   ],
   "source": [
    "def main(n=10, image_files=None, random_order=False, indexes=None):\n",
    "    resize = 800, 800\n",
    "    crop_engine = HybridEngine(padding=1.5)\n",
    "    \n",
    "    if image_files is None:\n",
    "        image_files = pinterestimages\n",
    "        \n",
    "    if random_order:\n",
    "        random.shuffle(image_files)\n",
    "   \n",
    "    image_files = image_files[:n]\n",
    "    \n",
    "    print('>'*len(image_files) + '*'*len(image_files))\n",
    "    \n",
    "    images = []\n",
    "    for image_file in image_files:\n",
    "        im = Image.open(image_file).convert('RGB')\n",
    "        im.filename = image_file\n",
    "        im.thumbnail(resize)\n",
    "        im.title = '{1}x{2}  {0}'.format(image_file, im.width, im.height)\n",
    "        im.features = crop_engine.find_features(image_file)\n",
    "        images.append(im)\n",
    "        print('<', end = '')\n",
    "    \n",
    "    return make_html(images)\n",
    "  \n",
    "images = glob.glob('./*.jpg')\n",
    "html = main(5, images, random_order=True)\n",
    "HTML(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haarcascade_eye.xml\r\n",
      "haarcascade_eye_tree_eyeglasses.xml\r\n",
      "haarcascade_frontalcatface.xml\r\n",
      "haarcascade_frontalcatface_extended.xml\r\n",
      "haarcascade_frontalface_alt.xml\r\n",
      "haarcascade_frontalface_alt2.xml\r\n",
      "haarcascade_frontalface_alt_tree.xml\r\n",
      "haarcascade_frontalface_default.xml\r\n",
      "haarcascade_fullbody.xml\r\n",
      "haarcascade_lefteye_2splits.xml\r\n",
      "haarcascade_licence_plate_rus_16stages.xml\r\n",
      "haarcascade_lowerbody.xml\r\n",
      "haarcascade_profileface.xml\r\n",
      "haarcascade_righteye_2splits.xml\r\n",
      "haarcascade_russian_plate_number.xml\r\n",
      "haarcascade_smile.xml\r\n",
      "haarcascade_upperbody.xml\r\n"
     ]
    }
   ],
   "source": [
    "!ls /usr/local/share/OpenCV/haarcascades/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
